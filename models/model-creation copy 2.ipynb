{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 13:14:01.886000: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-07 13:14:01.908240: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-07 13:14:01.908262: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-07 13:14:01.908278: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-07 13:14:01.912602: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.14.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 13:14:02.726963: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:14:02.729777: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:14:02.729858: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: ['/device:GPU:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 13:14:02.736766: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:14:02.736881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:14:02.736925: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:14:02.778313: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:14:02.778410: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:14:02.778460: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:14:02.778506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 14290 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "local_devices = device_lib.list_local_devices()\n",
    "gpus = [device.name for device in local_devices if device.device_type == 'GPU']\n",
    "print(\"Available GPUs:\", gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from pyswarm import pso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4\n",
       "0 -0.145 -0.145 -0.145 -0.145 -0.145\n",
       "1 -0.145 -0.145 -0.145 -0.145 -0.145\n",
       "2 -0.145 -0.145 -0.135 -0.145 -0.120\n",
       "3 -0.135 -0.145 -0.160 -0.155 -0.150\n",
       "4 -0.160 -0.155 -0.175 -0.180 -0.160"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('training.csv', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-600.2106, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 13:15:40.733770: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:15:40.733898: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:15:40.733941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:15:40.734010: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:15:40.734053: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:15:40.734092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14290 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_sum(tf.random.normal([1000, 1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras menggunakan GPU: ['/device:GPU:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 13:15:44.839654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:15:44.839816: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:15:44.839904: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:15:44.840027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:15:44.840115: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 13:15:44.840182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 14290 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "local_devices = device_lib.list_local_devices()\n",
    "gpus = [device.name for device in local_devices if device.device_type == 'GPU']\n",
    "if gpus:\n",
    "    print(\"Keras menggunakan GPU:\", gpus)\n",
    "else:\n",
    "    print(\"Keras menggunakan CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses ke-0\n",
      "Fit ke-0\n",
      "Fit ke-0 End\n",
      "1724/1724 [==============================] - 1s 563us/step - loss: 8.4704e-05\n",
      "Loss ke-0\n",
      "8.470435568597168e-05\n",
      "Proses ke-1\n",
      "Fit ke-1\n",
      "Fit ke-1 End\n",
      "1724/1724 [==============================] - 1s 567us/step - loss: 7.9450e-05\n",
      "Loss ke-1\n",
      "7.944973913254216e-05\n",
      "Proses ke-2\n",
      "Fit ke-2\n",
      "Fit ke-2 End\n",
      "1724/1724 [==============================] - 1s 575us/step - loss: 9.1963e-05\n",
      "Loss ke-2\n",
      "9.196317114401609e-05\n",
      "Proses ke-3\n",
      "Fit ke-3\n",
      "Fit ke-3 End\n",
      "1724/1724 [==============================] - 1s 571us/step - loss: 8.1538e-05\n",
      "Loss ke-3\n",
      "8.153810631483793e-05\n",
      "Proses ke-4\n",
      "Fit ke-4\n",
      "Fit ke-4 End\n",
      "1724/1724 [==============================] - 1s 568us/step - loss: 8.7273e-05\n",
      "Loss ke-4\n",
      "8.727297245059162e-05\n",
      "Proses ke-5\n",
      "Fit ke-5\n",
      "Fit ke-5 End\n",
      "1724/1724 [==============================] - 1s 567us/step - loss: 8.3098e-05\n",
      "Loss ke-5\n",
      "8.309764234581962e-05\n",
      "Proses ke-6\n",
      "Fit ke-6\n",
      "Fit ke-6 End\n",
      "1724/1724 [==============================] - 1s 608us/step - loss: 8.1756e-05\n",
      "Loss ke-6\n",
      "8.175594120984897e-05\n",
      "Proses ke-7\n",
      "Fit ke-7\n",
      "Fit ke-7 End\n",
      "1724/1724 [==============================] - 1s 573us/step - loss: 8.0946e-05\n",
      "Loss ke-7\n",
      "8.094553049886599e-05\n",
      "Proses ke-8\n",
      "Fit ke-8\n",
      "Fit ke-8 End\n",
      "1724/1724 [==============================] - 1s 568us/step - loss: 7.8444e-05\n",
      "Loss ke-8\n",
      "7.844425999792293e-05\n",
      "Proses ke-9\n",
      "Fit ke-9\n",
      "Fit ke-9 End\n",
      "1724/1724 [==============================] - 1s 584us/step - loss: 8.9044e-05\n",
      "Loss ke-9\n",
      "8.90442097443156e-05\n",
      "Proses ke-10\n",
      "Fit ke-10\n",
      "Fit ke-10 End\n",
      "1724/1724 [==============================] - 1s 583us/step - loss: 8.1738e-05\n",
      "Loss ke-10\n",
      "8.173751848516986e-05\n",
      "Proses ke-11\n",
      "Fit ke-11\n",
      "Fit ke-11 End\n",
      "1724/1724 [==============================] - 1s 592us/step - loss: 8.1185e-05\n",
      "Loss ke-11\n",
      "8.118508412735537e-05\n",
      "Proses ke-12\n",
      "Fit ke-12\n",
      "Fit ke-12 End\n",
      "1724/1724 [==============================] - 1s 605us/step - loss: 1.1940e-04\n",
      "Loss ke-12\n",
      "0.00011940087279072031\n",
      "Proses ke-13\n",
      "Fit ke-13\n",
      "Fit ke-13 End\n",
      "1724/1724 [==============================] - 1s 596us/step - loss: 8.9738e-05\n",
      "Loss ke-13\n",
      "8.973784861154854e-05\n",
      "Proses ke-14\n",
      "Fit ke-14\n",
      "Fit ke-14 End\n",
      "1724/1724 [==============================] - 1s 607us/step - loss: 7.7220e-05\n",
      "Loss ke-14\n",
      "7.721984729869291e-05\n",
      "Proses ke-15\n",
      "Fit ke-15\n",
      "Fit ke-15 End\n",
      "1724/1724 [==============================] - 1s 592us/step - loss: 8.4261e-05\n",
      "Loss ke-15\n",
      "8.426140993833542e-05\n",
      "Proses ke-16\n",
      "Fit ke-16\n",
      "Fit ke-16 End\n",
      "1724/1724 [==============================] - 1s 587us/step - loss: 8.5657e-05\n",
      "Loss ke-16\n",
      "8.565661846660078e-05\n",
      "Proses ke-17\n",
      "Fit ke-17\n",
      "Fit ke-17 End\n",
      "1724/1724 [==============================] - 1s 579us/step - loss: 8.5837e-05\n",
      "Loss ke-17\n",
      "8.583659655414522e-05\n",
      "Proses ke-18\n",
      "Fit ke-18\n",
      "Fit ke-18 End\n",
      "1724/1724 [==============================] - 1s 582us/step - loss: 7.9608e-05\n",
      "Loss ke-18\n",
      "7.960781658766791e-05\n",
      "Proses ke-19\n",
      "Fit ke-19\n",
      "Fit ke-19 End\n",
      "1724/1724 [==============================] - 1s 548us/step - loss: 8.4271e-05\n",
      "Loss ke-19\n",
      "8.427120337728411e-05\n",
      "Proses ke-20\n",
      "Fit ke-20\n",
      "Fit ke-20 End\n",
      "1724/1724 [==============================] - 1s 585us/step - loss: 8.2765e-05\n",
      "Loss ke-20\n",
      "8.276501466752961e-05\n",
      "Proses ke-21\n",
      "Fit ke-21\n",
      "Fit ke-21 End\n",
      "1724/1724 [==============================] - 1s 584us/step - loss: 8.0653e-05\n",
      "Loss ke-21\n",
      "8.06526149972342e-05\n",
      "Proses ke-22\n",
      "Fit ke-22\n",
      "Fit ke-22 End\n",
      "1724/1724 [==============================] - 1s 582us/step - loss: 8.4400e-05\n",
      "Loss ke-22\n",
      "8.440046076430008e-05\n",
      "Proses ke-23\n",
      "Fit ke-23\n",
      "Fit ke-23 End\n",
      "1724/1724 [==============================] - 1s 604us/step - loss: 1.3422e-04\n",
      "Loss ke-23\n",
      "0.00013422337360680103\n",
      "Proses ke-24\n",
      "Fit ke-24\n",
      "Fit ke-24 End\n",
      "1724/1724 [==============================] - 1s 583us/step - loss: 8.2825e-05\n",
      "Loss ke-24\n",
      "8.282456110464409e-05\n",
      "Proses ke-25\n",
      "Fit ke-25\n",
      "Fit ke-25 End\n",
      "1724/1724 [==============================] - 1s 551us/step - loss: 8.6488e-05\n",
      "Loss ke-25\n",
      "8.648847142467275e-05\n",
      "Proses ke-26\n",
      "Fit ke-26\n",
      "Fit ke-26 End\n",
      "1724/1724 [==============================] - 1s 571us/step - loss: 8.6907e-05\n",
      "Loss ke-26\n",
      "8.690661343280226e-05\n",
      "Proses ke-27\n",
      "Fit ke-27\n",
      "Fit ke-27 End\n",
      "1724/1724 [==============================] - 1s 611us/step - loss: 9.0426e-05\n",
      "Loss ke-27\n",
      "9.042621968546882e-05\n",
      "Proses ke-28\n",
      "Fit ke-28\n",
      "Fit ke-28 End\n",
      "1724/1724 [==============================] - 1s 580us/step - loss: 8.0518e-05\n",
      "Loss ke-28\n",
      "8.051835902733728e-05\n",
      "Proses ke-29\n",
      "Fit ke-29\n",
      "Fit ke-29 End\n",
      "1724/1724 [==============================] - 1s 597us/step - loss: 1.2268e-04\n",
      "Loss ke-29\n",
      "0.00012267603597138077\n",
      "Proses ke-30\n",
      "Fit ke-30\n",
      "Fit ke-30 End\n",
      "1724/1724 [==============================] - 1s 599us/step - loss: 9.7020e-05\n",
      "Loss ke-30\n",
      "9.702014358481392e-05\n",
      "Proses ke-31\n",
      "Fit ke-31\n",
      "Fit ke-31 End\n",
      "1724/1724 [==============================] - 1s 597us/step - loss: 7.8850e-05\n",
      "Loss ke-31\n",
      "7.885007653385401e-05\n",
      "Proses ke-32\n",
      "Fit ke-32\n",
      "Fit ke-32 End\n",
      "1724/1724 [==============================] - 1s 598us/step - loss: 7.9076e-05\n",
      "Loss ke-32\n",
      "7.907644612714648e-05\n",
      "Proses ke-33\n",
      "Fit ke-33\n",
      "Fit ke-33 End\n",
      "1724/1724 [==============================] - 1s 591us/step - loss: 8.3437e-05\n",
      "Loss ke-33\n",
      "8.343679655808955e-05\n",
      "Proses ke-34\n",
      "Fit ke-34\n",
      "Fit ke-34 End\n",
      "1724/1724 [==============================] - 1s 586us/step - loss: 7.8028e-05\n",
      "Loss ke-34\n",
      "7.802779146004468e-05\n",
      "Proses ke-35\n",
      "Fit ke-35\n",
      "Fit ke-35 End\n",
      "1724/1724 [==============================] - 1s 586us/step - loss: 7.8151e-05\n",
      "Loss ke-35\n",
      "7.815083517925814e-05\n",
      "Proses ke-36\n",
      "Fit ke-36\n",
      "Fit ke-36 End\n",
      "1724/1724 [==============================] - 1s 580us/step - loss: 8.4763e-05\n",
      "Loss ke-36\n",
      "8.476338553009555e-05\n",
      "Proses ke-37\n",
      "Fit ke-37\n",
      "Fit ke-37 End\n",
      "1724/1724 [==============================] - 1s 588us/step - loss: 8.4801e-05\n",
      "Loss ke-37\n",
      "8.48009149194695e-05\n",
      "Proses ke-38\n",
      "Fit ke-38\n",
      "Fit ke-38 End\n",
      "1724/1724 [==============================] - 1s 569us/step - loss: 7.8960e-05\n",
      "Loss ke-38\n",
      "7.896001625340432e-05\n",
      "Proses ke-39\n",
      "Fit ke-39\n",
      "Fit ke-39 End\n",
      "1724/1724 [==============================] - 1s 565us/step - loss: 9.3603e-05\n",
      "Loss ke-39\n",
      "9.360341937281191e-05\n",
      "Proses ke-40\n",
      "Fit ke-40\n",
      "Fit ke-40 End\n",
      "1724/1724 [==============================] - 1s 570us/step - loss: 7.5325e-05\n",
      "Loss ke-40\n",
      "7.532507152063772e-05\n",
      "Proses ke-41\n",
      "Fit ke-41\n",
      "Fit ke-41 End\n",
      "1724/1724 [==============================] - 1s 555us/step - loss: 8.1547e-05\n",
      "Loss ke-41\n",
      "8.15473758848384e-05\n",
      "Proses ke-42\n",
      "Fit ke-42\n",
      "Fit ke-42 End\n",
      "1724/1724 [==============================] - 1s 568us/step - loss: 1.2264e-04\n",
      "Loss ke-42\n",
      "0.00012263975804671645\n",
      "Proses ke-43\n",
      "Fit ke-43\n",
      "Fit ke-43 End\n",
      "1724/1724 [==============================] - 1s 555us/step - loss: 8.0888e-05\n",
      "Loss ke-43\n",
      "8.088781760307029e-05\n",
      "Proses ke-44\n",
      "Fit ke-44\n",
      "Fit ke-44 End\n",
      "1724/1724 [==============================] - 1s 554us/step - loss: 7.4505e-05\n",
      "Loss ke-44\n",
      "7.450475823134184e-05\n",
      "Proses ke-45\n",
      "Fit ke-45\n",
      "Fit ke-45 End\n",
      "1724/1724 [==============================] - 1s 558us/step - loss: 7.6706e-05\n",
      "Loss ke-45\n",
      "7.670615013921633e-05\n",
      "Proses ke-46\n",
      "Fit ke-46\n",
      "Fit ke-46 End\n",
      "1724/1724 [==============================] - 1s 556us/step - loss: 8.0440e-05\n",
      "Loss ke-46\n",
      "8.04397786851041e-05\n",
      "Proses ke-47\n",
      "Fit ke-47\n",
      "Fit ke-47 End\n",
      "1724/1724 [==============================] - 1s 569us/step - loss: 8.4472e-05\n",
      "Loss ke-47\n",
      "8.447209984296933e-05\n",
      "Proses ke-48\n",
      "Fit ke-48\n",
      "Fit ke-48 End\n",
      "1724/1724 [==============================] - 1s 550us/step - loss: 9.4400e-05\n",
      "Loss ke-48\n",
      "9.439980931347236e-05\n",
      "Proses ke-49\n",
      "Fit ke-49\n",
      "Fit ke-49 End\n",
      "1724/1724 [==============================] - 1s 578us/step - loss: 8.9264e-05\n",
      "Loss ke-49\n",
      "8.926368172978982e-05\n",
      "Proses ke-50\n",
      "Fit ke-50\n",
      "Fit ke-50 End\n",
      "1724/1724 [==============================] - 1s 552us/step - loss: 8.0348e-05\n",
      "Loss ke-50\n",
      "8.034835627768189e-05\n",
      "Proses ke-51\n",
      "Fit ke-51\n",
      "Fit ke-51 End\n",
      "1724/1724 [==============================] - 1s 563us/step - loss: 8.2780e-05\n",
      "Loss ke-51\n",
      "8.278003224404529e-05\n",
      "Proses ke-52\n",
      "Fit ke-52\n",
      "Fit ke-52 End\n",
      "1724/1724 [==============================] - 1s 568us/step - loss: 8.1516e-05\n",
      "Loss ke-52\n",
      "8.151550719048828e-05\n",
      "Proses ke-53\n",
      "Fit ke-53\n",
      "Fit ke-53 End\n",
      "1724/1724 [==============================] - 1s 577us/step - loss: 7.9300e-05\n",
      "Loss ke-53\n",
      "7.930022547952831e-05\n",
      "Proses ke-54\n",
      "Fit ke-54\n",
      "Fit ke-54 End\n",
      "1724/1724 [==============================] - 1s 552us/step - loss: 8.2117e-05\n",
      "Loss ke-54\n",
      "8.21165886009112e-05\n",
      "Proses ke-55\n",
      "Fit ke-55\n",
      "Fit ke-55 End\n",
      "1724/1724 [==============================] - 1s 564us/step - loss: 8.1737e-05\n",
      "Loss ke-55\n",
      "8.173735113814473e-05\n",
      "Proses ke-56\n",
      "Fit ke-56\n",
      "Fit ke-56 End\n",
      "1724/1724 [==============================] - 1s 543us/step - loss: 8.2070e-05\n",
      "Loss ke-56\n",
      "8.206976053770632e-05\n",
      "Proses ke-57\n",
      "Fit ke-57\n",
      "Fit ke-57 End\n",
      "1724/1724 [==============================] - 1s 577us/step - loss: 8.1058e-05\n",
      "Loss ke-57\n",
      "8.105781307676807e-05\n",
      "Proses ke-58\n",
      "Fit ke-58\n",
      "Fit ke-58 End\n",
      "1724/1724 [==============================] - 1s 552us/step - loss: 1.1592e-04\n",
      "Loss ke-58\n",
      "0.00011592131340876222\n",
      "Proses ke-59\n",
      "Fit ke-59\n",
      "Fit ke-59 End\n",
      "1724/1724 [==============================] - 1s 559us/step - loss: 7.8364e-05\n",
      "Loss ke-59\n",
      "7.83635041443631e-05\n",
      "Proses ke-60\n",
      "Fit ke-60\n",
      "Fit ke-60 End\n",
      "1724/1724 [==============================] - 1s 540us/step - loss: 9.2977e-05\n",
      "Loss ke-60\n",
      "9.29771558730863e-05\n",
      "Proses ke-61\n",
      "Fit ke-61\n",
      "Fit ke-61 End\n",
      "1724/1724 [==============================] - 1s 558us/step - loss: 8.2945e-05\n",
      "Loss ke-61\n",
      "8.294467261293903e-05\n",
      "Proses ke-62\n",
      "Fit ke-62\n",
      "Fit ke-62 End\n",
      "1724/1724 [==============================] - 1s 532us/step - loss: 8.0243e-05\n",
      "Loss ke-62\n",
      "8.02430440671742e-05\n",
      "Proses ke-63\n",
      "Fit ke-63\n",
      "Fit ke-63 End\n",
      "1724/1724 [==============================] - 1s 564us/step - loss: 8.0325e-05\n",
      "Loss ke-63\n",
      "8.03251241450198e-05\n",
      "Proses ke-64\n",
      "Fit ke-64\n",
      "Fit ke-64 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 7.7502e-05\n",
      "Loss ke-64\n",
      "7.750213262625039e-05\n",
      "Proses ke-65\n",
      "Fit ke-65\n",
      "Fit ke-65 End\n",
      "1724/1724 [==============================] - 1s 565us/step - loss: 8.1874e-05\n",
      "Loss ke-65\n",
      "8.187392813852057e-05\n",
      "Proses ke-66\n",
      "Fit ke-66\n",
      "Fit ke-66 End\n",
      "1724/1724 [==============================] - 1s 562us/step - loss: 1.1064e-04\n",
      "Loss ke-66\n",
      "0.00011064266436733305\n",
      "Proses ke-67\n",
      "Fit ke-67\n",
      "Fit ke-67 End\n",
      "1724/1724 [==============================] - 1s 590us/step - loss: 9.6307e-05\n",
      "Loss ke-67\n",
      "9.630724525777623e-05\n",
      "Proses ke-68\n",
      "Fit ke-68\n",
      "Fit ke-68 End\n",
      "1724/1724 [==============================] - 1s 582us/step - loss: 9.5503e-05\n",
      "Loss ke-68\n",
      "9.550287359161302e-05\n",
      "Proses ke-69\n",
      "Fit ke-69\n",
      "Fit ke-69 End\n",
      "1724/1724 [==============================] - 1s 576us/step - loss: 7.8520e-05\n",
      "Loss ke-69\n",
      "7.851978443795815e-05\n",
      "Proses ke-70\n",
      "Fit ke-70\n",
      "Fit ke-70 End\n",
      "1724/1724 [==============================] - 1s 569us/step - loss: 7.5478e-05\n",
      "Loss ke-70\n",
      "7.547843415522948e-05\n",
      "Proses ke-71\n",
      "Fit ke-71\n",
      "Fit ke-71 End\n",
      "1724/1724 [==============================] - 1s 566us/step - loss: 8.3133e-05\n",
      "Loss ke-71\n",
      "8.313330181408674e-05\n",
      "Proses ke-72\n",
      "Fit ke-72\n",
      "Fit ke-72 End\n",
      "1724/1724 [==============================] - 1s 567us/step - loss: 1.1293e-04\n",
      "Loss ke-72\n",
      "0.00011293030547676608\n",
      "Proses ke-73\n",
      "Fit ke-73\n",
      "Fit ke-73 End\n",
      "1724/1724 [==============================] - 1s 564us/step - loss: 8.1299e-05\n",
      "Loss ke-73\n",
      "8.12985745142214e-05\n",
      "Proses ke-74\n",
      "Fit ke-74\n",
      "Fit ke-74 End\n",
      "1724/1724 [==============================] - 1s 569us/step - loss: 7.6175e-05\n",
      "Loss ke-74\n",
      "7.617515802849084e-05\n",
      "Proses ke-75\n",
      "Fit ke-75\n",
      "Fit ke-75 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 7.6380e-05\n",
      "Loss ke-75\n",
      "7.637974340468645e-05\n",
      "Proses ke-76\n",
      "Fit ke-76\n",
      "Fit ke-76 End\n",
      "1724/1724 [==============================] - 1s 562us/step - loss: 1.0039e-04\n",
      "Loss ke-76\n",
      "0.00010039260087069124\n",
      "Proses ke-77\n",
      "Fit ke-77\n",
      "Fit ke-77 End\n",
      "1724/1724 [==============================] - 1s 557us/step - loss: 1.0813e-04\n",
      "Loss ke-77\n",
      "0.0001081308801076375\n",
      "Proses ke-78\n",
      "Fit ke-78\n",
      "Fit ke-78 End\n",
      "1724/1724 [==============================] - 1s 574us/step - loss: 1.0868e-04\n",
      "Loss ke-78\n",
      "0.00010868030221899971\n",
      "Proses ke-79\n",
      "Fit ke-79\n",
      "Fit ke-79 End\n",
      "1724/1724 [==============================] - 1s 572us/step - loss: 8.0450e-05\n",
      "Loss ke-79\n",
      "8.045020513236523e-05\n",
      "Proses ke-80\n",
      "Fit ke-80\n",
      "Fit ke-80 End\n",
      "1724/1724 [==============================] - 1s 559us/step - loss: 7.6438e-05\n",
      "Loss ke-80\n",
      "7.643778371857479e-05\n",
      "Proses ke-81\n",
      "Fit ke-81\n",
      "Fit ke-81 End\n",
      "1724/1724 [==============================] - 1s 556us/step - loss: 9.5244e-05\n",
      "Loss ke-81\n",
      "9.524376218905672e-05\n",
      "Proses ke-82\n",
      "Fit ke-82\n",
      "Fit ke-82 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 1.1269e-04\n",
      "Loss ke-82\n",
      "0.00011268624075455591\n",
      "Proses ke-83\n",
      "Fit ke-83\n",
      "Fit ke-83 End\n",
      "1724/1724 [==============================] - 1s 573us/step - loss: 8.2370e-05\n",
      "Loss ke-83\n",
      "8.236982830567285e-05\n",
      "Proses ke-84\n",
      "Fit ke-84\n",
      "Fit ke-84 End\n",
      "1724/1724 [==============================] - 1s 558us/step - loss: 7.7079e-05\n",
      "Loss ke-84\n",
      "7.707913755439222e-05\n",
      "Proses ke-85\n",
      "Fit ke-85\n",
      "Fit ke-85 End\n",
      "1724/1724 [==============================] - 1s 581us/step - loss: 7.8875e-05\n",
      "Loss ke-85\n",
      "7.887489482527599e-05\n",
      "Proses ke-86\n",
      "Fit ke-86\n",
      "Fit ke-86 End\n",
      "1724/1724 [==============================] - 1s 584us/step - loss: 8.2657e-05\n",
      "Loss ke-86\n",
      "8.265701035270467e-05\n",
      "Proses ke-87\n",
      "Fit ke-87\n",
      "Fit ke-87 End\n",
      "1724/1724 [==============================] - 1s 585us/step - loss: 9.9286e-05\n",
      "Loss ke-87\n",
      "9.928648069035262e-05\n",
      "Proses ke-88\n",
      "Fit ke-88\n",
      "Fit ke-88 End\n",
      "1724/1724 [==============================] - 1s 579us/step - loss: 1.3859e-04\n",
      "Loss ke-88\n",
      "0.00013859268801752478\n",
      "Proses ke-89\n",
      "Fit ke-89\n",
      "Fit ke-89 End\n",
      "1724/1724 [==============================] - 1s 579us/step - loss: 8.0194e-05\n",
      "Loss ke-89\n",
      "8.019413508009166e-05\n",
      "Proses ke-90\n",
      "Fit ke-90\n",
      "Fit ke-90 End\n",
      "1724/1724 [==============================] - 1s 573us/step - loss: 8.2097e-05\n",
      "Loss ke-90\n",
      "8.20970453787595e-05\n",
      "Proses ke-91\n",
      "Fit ke-91\n",
      "Fit ke-91 End\n",
      "1724/1724 [==============================] - 1s 559us/step - loss: 8.2877e-05\n",
      "Loss ke-91\n",
      "8.287692617159337e-05\n",
      "Proses ke-92\n",
      "Fit ke-92\n",
      "Fit ke-92 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 8.4981e-05\n",
      "Loss ke-92\n",
      "8.498091483488679e-05\n",
      "Proses ke-93\n",
      "Fit ke-93\n",
      "Fit ke-93 End\n",
      "1724/1724 [==============================] - 1s 559us/step - loss: 8.1578e-05\n",
      "Loss ke-93\n",
      "8.157832780852914e-05\n",
      "Proses ke-94\n",
      "Fit ke-94\n",
      "Fit ke-94 End\n",
      "1724/1724 [==============================] - 1s 575us/step - loss: 7.7070e-05\n",
      "Loss ke-94\n",
      "7.707048644078895e-05\n",
      "Proses ke-95\n",
      "Fit ke-95\n",
      "Fit ke-95 End\n",
      "1724/1724 [==============================] - 1s 558us/step - loss: 7.5966e-05\n",
      "Loss ke-95\n",
      "7.596610521432012e-05\n",
      "Proses ke-96\n",
      "Fit ke-96\n",
      "Fit ke-96 End\n",
      "1724/1724 [==============================] - 1s 557us/step - loss: 8.0606e-05\n",
      "Loss ke-96\n",
      "8.060607069637626e-05\n",
      "Proses ke-97\n",
      "Fit ke-97\n",
      "Fit ke-97 End\n",
      "1724/1724 [==============================] - 1s 577us/step - loss: 8.1070e-05\n",
      "Loss ke-97\n",
      "8.106997120194137e-05\n",
      "Proses ke-98\n",
      "Fit ke-98\n",
      "Fit ke-98 End\n",
      "1724/1724 [==============================] - 1s 573us/step - loss: 1.0808e-04\n",
      "Loss ke-98\n",
      "0.00010808361548697576\n",
      "Proses ke-99\n",
      "Fit ke-99\n",
      "Fit ke-99 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 8.4198e-05\n",
      "Loss ke-99\n",
      "8.41975852381438e-05\n",
      "Proses ke-100\n",
      "Fit ke-100\n",
      "Fit ke-100 End\n",
      "1724/1724 [==============================] - 1s 562us/step - loss: 8.0448e-05\n",
      "Loss ke-100\n",
      "8.044778951443732e-05\n",
      "Proses ke-101\n",
      "Fit ke-101\n",
      "Fit ke-101 End\n",
      "1724/1724 [==============================] - 1s 563us/step - loss: 8.4682e-05\n",
      "Loss ke-101\n",
      "8.468237501801923e-05\n",
      "Proses ke-102\n",
      "Fit ke-102\n",
      "Fit ke-102 End\n",
      "1724/1724 [==============================] - 1s 560us/step - loss: 8.6293e-05\n",
      "Loss ke-102\n",
      "8.629255171399564e-05\n",
      "Proses ke-103\n",
      "Fit ke-103\n",
      "Fit ke-103 End\n",
      "1724/1724 [==============================] - 1s 556us/step - loss: 7.7960e-05\n",
      "Loss ke-103\n",
      "7.795976853230968e-05\n",
      "Proses ke-104\n",
      "Fit ke-104\n",
      "Fit ke-104 End\n",
      "1724/1724 [==============================] - 1s 571us/step - loss: 7.7783e-05\n",
      "Loss ke-104\n",
      "7.778273720759898e-05\n",
      "Proses ke-105\n",
      "Fit ke-105\n",
      "Fit ke-105 End\n",
      "1724/1724 [==============================] - 1s 560us/step - loss: 7.7317e-05\n",
      "Loss ke-105\n",
      "7.73165884311311e-05\n",
      "Proses ke-106\n",
      "Fit ke-106\n",
      "Fit ke-106 End\n",
      "1724/1724 [==============================] - 1s 570us/step - loss: 7.9222e-05\n",
      "Loss ke-106\n",
      "7.922207441879436e-05\n",
      "Proses ke-107\n",
      "Fit ke-107\n",
      "Fit ke-107 End\n",
      "1724/1724 [==============================] - 1s 578us/step - loss: 8.0701e-05\n",
      "Loss ke-107\n",
      "8.070080366451293e-05\n",
      "Proses ke-108\n",
      "Fit ke-108\n",
      "Fit ke-108 End\n",
      "1724/1724 [==============================] - 1s 564us/step - loss: 8.5271e-05\n",
      "Loss ke-108\n",
      "8.527066529495642e-05\n",
      "Proses ke-109\n",
      "Fit ke-109\n",
      "Fit ke-109 End\n",
      "1724/1724 [==============================] - 1s 550us/step - loss: 8.5338e-05\n",
      "Loss ke-109\n",
      "8.53378587635234e-05\n",
      "Proses ke-110\n",
      "Fit ke-110\n",
      "Fit ke-110 End\n",
      "1724/1724 [==============================] - 1s 557us/step - loss: 7.7604e-05\n",
      "Loss ke-110\n",
      "7.760358130326495e-05\n",
      "Proses ke-111\n",
      "Fit ke-111\n",
      "Fit ke-111 End\n",
      "1724/1724 [==============================] - 1s 564us/step - loss: 8.2749e-05\n",
      "Loss ke-111\n",
      "8.274912397610024e-05\n",
      "Proses ke-112\n",
      "Fit ke-112\n",
      "Fit ke-112 End\n",
      "1724/1724 [==============================] - 1s 541us/step - loss: 8.0644e-05\n",
      "Loss ke-112\n",
      "8.064399298746139e-05\n",
      "Proses ke-113\n",
      "Fit ke-113\n",
      "Fit ke-113 End\n",
      "1724/1724 [==============================] - 1s 559us/step - loss: 8.1592e-05\n",
      "Loss ke-113\n",
      "8.159234857885167e-05\n",
      "Proses ke-114\n",
      "Fit ke-114\n",
      "Fit ke-114 End\n",
      "1724/1724 [==============================] - 1s 540us/step - loss: 7.7183e-05\n",
      "Loss ke-114\n",
      "7.71828053984791e-05\n",
      "Proses ke-115\n",
      "Fit ke-115\n",
      "Fit ke-115 End\n",
      "1724/1724 [==============================] - 1s 574us/step - loss: 7.7206e-05\n",
      "Loss ke-115\n",
      "7.720608118688688e-05\n",
      "Proses ke-116\n",
      "Fit ke-116\n",
      "Fit ke-116 End\n",
      "1724/1724 [==============================] - 1s 578us/step - loss: 8.4958e-05\n",
      "Loss ke-116\n",
      "8.495829388266429e-05\n",
      "Proses ke-117\n",
      "Fit ke-117\n",
      "Fit ke-117 End\n",
      "1724/1724 [==============================] - 1s 559us/step - loss: 7.8542e-05\n",
      "Loss ke-117\n",
      "7.854177238186821e-05\n",
      "Proses ke-118\n",
      "Fit ke-118\n",
      "Fit ke-118 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 8.0624e-05\n",
      "Loss ke-118\n",
      "8.062386768870056e-05\n",
      "Proses ke-119\n",
      "Fit ke-119\n",
      "Fit ke-119 End\n",
      "1724/1724 [==============================] - 1s 553us/step - loss: 8.2552e-05\n",
      "Loss ke-119\n",
      "8.255192369688302e-05\n",
      "Proses ke-120\n",
      "Fit ke-120\n",
      "Fit ke-120 End\n",
      "1724/1724 [==============================] - 1s 554us/step - loss: 7.7749e-05\n",
      "Loss ke-120\n",
      "7.774906407576054e-05\n",
      "Proses ke-121\n",
      "Fit ke-121\n",
      "Fit ke-121 End\n",
      "1724/1724 [==============================] - 1s 556us/step - loss: 8.0676e-05\n",
      "Loss ke-121\n",
      "8.067603630479425e-05\n",
      "Proses ke-122\n",
      "Fit ke-122\n",
      "Fit ke-122 End\n",
      "1724/1724 [==============================] - 1s 560us/step - loss: 8.2389e-05\n",
      "Loss ke-122\n",
      "8.238897135015577e-05\n",
      "Proses ke-123\n",
      "Fit ke-123\n",
      "Fit ke-123 End\n",
      "1724/1724 [==============================] - 1s 541us/step - loss: 7.9264e-05\n",
      "Loss ke-123\n",
      "7.92644132161513e-05\n",
      "Proses ke-124\n",
      "Fit ke-124\n",
      "Fit ke-124 End\n",
      "1724/1724 [==============================] - 1s 557us/step - loss: 7.6223e-05\n",
      "Loss ke-124\n",
      "7.622276461916044e-05\n",
      "Proses ke-125\n",
      "Fit ke-125\n",
      "Fit ke-125 End\n",
      "1724/1724 [==============================] - 1s 553us/step - loss: 7.6459e-05\n",
      "Loss ke-125\n",
      "7.645904406672344e-05\n",
      "Proses ke-126\n",
      "Fit ke-126\n",
      "Fit ke-126 End\n",
      "1724/1724 [==============================] - 1s 577us/step - loss: 7.8808e-05\n",
      "Loss ke-126\n",
      "7.880825432948768e-05\n",
      "Proses ke-127\n",
      "Fit ke-127\n",
      "Fit ke-127 End\n",
      "1724/1724 [==============================] - 1s 549us/step - loss: 8.3176e-05\n",
      "Loss ke-127\n",
      "8.317585161421448e-05\n",
      "Proses ke-128\n",
      "Fit ke-128\n",
      "Fit ke-128 End\n",
      "1724/1724 [==============================] - 1s 558us/step - loss: 8.9171e-05\n",
      "Loss ke-128\n",
      "8.917100058170035e-05\n",
      "Proses ke-129\n",
      "Fit ke-129\n",
      "Fit ke-129 End\n",
      "1724/1724 [==============================] - 1s 568us/step - loss: 8.1176e-05\n",
      "Loss ke-129\n",
      "8.117593824863434e-05\n",
      "Proses ke-130\n",
      "Fit ke-130\n",
      "Fit ke-130 End\n",
      "1724/1724 [==============================] - 1s 542us/step - loss: 8.0145e-05\n",
      "Loss ke-130\n",
      "8.014451304916292e-05\n",
      "Proses ke-131\n",
      "Fit ke-131\n",
      "Fit ke-131 End\n",
      "1724/1724 [==============================] - 1s 572us/step - loss: 7.7874e-05\n",
      "Loss ke-131\n",
      "7.787447248119861e-05\n",
      "Proses ke-132\n",
      "Fit ke-132\n",
      "Fit ke-132 End\n",
      "1724/1724 [==============================] - 1s 557us/step - loss: 8.2353e-05\n",
      "Loss ke-132\n",
      "8.235332643380389e-05\n",
      "Proses ke-133\n",
      "Fit ke-133\n",
      "Fit ke-133 End\n",
      "1724/1724 [==============================] - 1s 566us/step - loss: 7.6125e-05\n",
      "Loss ke-133\n",
      "7.612531044287607e-05\n",
      "Proses ke-134\n",
      "Fit ke-134\n",
      "Fit ke-134 End\n",
      "1724/1724 [==============================] - 1s 560us/step - loss: 7.6888e-05\n",
      "Loss ke-134\n",
      "7.688754703849554e-05\n",
      "Proses ke-135\n",
      "Fit ke-135\n",
      "Fit ke-135 End\n",
      "1724/1724 [==============================] - 1s 567us/step - loss: 7.7369e-05\n",
      "Loss ke-135\n",
      "7.736890984233469e-05\n",
      "Proses ke-136\n",
      "Fit ke-136\n",
      "Fit ke-136 End\n",
      "1724/1724 [==============================] - 1s 573us/step - loss: 8.4772e-05\n",
      "Loss ke-136\n",
      "8.477152732666582e-05\n",
      "Proses ke-137\n",
      "Fit ke-137\n",
      "Fit ke-137 End\n",
      "1724/1724 [==============================] - 1s 567us/step - loss: 8.0606e-05\n",
      "Loss ke-137\n",
      "8.060577238211408e-05\n",
      "Proses ke-138\n",
      "Fit ke-138\n",
      "Fit ke-138 End\n",
      "1724/1724 [==============================] - 1s 558us/step - loss: 8.6540e-05\n",
      "Loss ke-138\n",
      "8.653991244500503e-05\n",
      "Proses ke-139\n",
      "Fit ke-139\n",
      "Fit ke-139 End\n",
      "1724/1724 [==============================] - 1s 552us/step - loss: 7.7118e-05\n",
      "Loss ke-139\n",
      "7.711817306699231e-05\n",
      "Proses ke-140\n",
      "Fit ke-140\n",
      "Fit ke-140 End\n",
      "1724/1724 [==============================] - 1s 553us/step - loss: 8.1589e-05\n",
      "Loss ke-140\n",
      "8.158944547176361e-05\n",
      "Proses ke-141\n",
      "Fit ke-141\n",
      "Fit ke-141 End\n",
      "1724/1724 [==============================] - 1s 557us/step - loss: 8.4168e-05\n",
      "Loss ke-141\n",
      "8.416800847044215e-05\n",
      "Proses ke-142\n",
      "Fit ke-142\n",
      "Fit ke-142 End\n",
      "1724/1724 [==============================] - 1s 570us/step - loss: 8.1188e-05\n",
      "Loss ke-142\n",
      "8.118811820168048e-05\n",
      "Proses ke-143\n",
      "Fit ke-143\n",
      "Fit ke-143 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 7.7913e-05\n",
      "Loss ke-143\n",
      "7.791331881890073e-05\n",
      "Proses ke-144\n",
      "Fit ke-144\n",
      "Fit ke-144 End\n",
      "1724/1724 [==============================] - 1s 551us/step - loss: 7.5622e-05\n",
      "Loss ke-144\n",
      "7.56221852498129e-05\n",
      "Proses ke-145\n",
      "Fit ke-145\n",
      "Fit ke-145 End\n",
      "1724/1724 [==============================] - 1s 577us/step - loss: 7.4142e-05\n",
      "Loss ke-145\n",
      "7.41421536076814e-05\n",
      "Proses ke-146\n",
      "Fit ke-146\n",
      "Fit ke-146 End\n",
      "1724/1724 [==============================] - 1s 569us/step - loss: 8.5115e-05\n",
      "Loss ke-146\n",
      "8.51153235998936e-05\n",
      "Proses ke-147\n",
      "Fit ke-147\n",
      "Fit ke-147 End\n",
      "1724/1724 [==============================] - 1s 571us/step - loss: 8.1654e-05\n",
      "Loss ke-147\n",
      "8.165417239069939e-05\n",
      "Proses ke-148\n",
      "Fit ke-148\n",
      "Fit ke-148 End\n",
      "1724/1724 [==============================] - 1s 567us/step - loss: 1.0966e-04\n",
      "Loss ke-148\n",
      "0.00010966014087898657\n",
      "Proses ke-149\n",
      "Fit ke-149\n",
      "Fit ke-149 End\n",
      "1724/1724 [==============================] - 1s 573us/step - loss: 8.2684e-05\n",
      "Loss ke-149\n",
      "8.268353849416599e-05\n",
      "Proses ke-150\n",
      "Fit ke-150\n",
      "Fit ke-150 End\n",
      "1724/1724 [==============================] - 1s 576us/step - loss: 8.4790e-05\n",
      "Loss ke-150\n",
      "8.479032840114087e-05\n",
      "Proses ke-151\n",
      "Fit ke-151\n",
      "Fit ke-151 End\n",
      "1724/1724 [==============================] - 1s 560us/step - loss: 9.2268e-05\n",
      "Loss ke-151\n",
      "9.226834663422778e-05\n",
      "Proses ke-152\n",
      "Fit ke-152\n",
      "Fit ke-152 End\n",
      "1724/1724 [==============================] - 1s 569us/step - loss: 7.9431e-05\n",
      "Loss ke-152\n",
      "7.943058881210163e-05\n",
      "Proses ke-153\n",
      "Fit ke-153\n",
      "Fit ke-153 End\n",
      "1724/1724 [==============================] - 1s 542us/step - loss: 7.7158e-05\n",
      "Loss ke-153\n",
      "7.715782703598961e-05\n",
      "Proses ke-154\n",
      "Fit ke-154\n",
      "Fit ke-154 End\n",
      "1724/1724 [==============================] - 1s 553us/step - loss: 7.5180e-05\n",
      "Loss ke-154\n",
      "7.517966878367588e-05\n",
      "Proses ke-155\n",
      "Fit ke-155\n",
      "Fit ke-155 End\n",
      "1724/1724 [==============================] - 1s 558us/step - loss: 7.8559e-05\n",
      "Loss ke-155\n",
      "7.855940202716738e-05\n",
      "Proses ke-156\n",
      "Fit ke-156\n",
      "Fit ke-156 End\n",
      "1724/1724 [==============================] - 1s 566us/step - loss: 8.3018e-05\n",
      "Loss ke-156\n",
      "8.30182689242065e-05\n",
      "Proses ke-157\n",
      "Fit ke-157\n",
      "Fit ke-157 End\n",
      "1724/1724 [==============================] - 1s 582us/step - loss: 8.2345e-05\n",
      "Loss ke-157\n",
      "8.234496635850519e-05\n",
      "Proses ke-158\n",
      "Fit ke-158\n",
      "Fit ke-158 End\n",
      "1724/1724 [==============================] - 1s 562us/step - loss: 1.1073e-04\n",
      "Loss ke-158\n",
      "0.00011072822235291824\n",
      "Proses ke-159\n",
      "Fit ke-159\n",
      "Fit ke-159 End\n",
      "1724/1724 [==============================] - 1s 564us/step - loss: 7.9490e-05\n",
      "Loss ke-159\n",
      "7.948993152240291e-05\n",
      "Proses ke-160\n",
      "Fit ke-160\n",
      "Fit ke-160 End\n",
      "1724/1724 [==============================] - 1s 548us/step - loss: 8.1586e-05\n",
      "Loss ke-160\n",
      "8.158626587828621e-05\n",
      "Proses ke-161\n",
      "Fit ke-161\n",
      "Fit ke-161 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 7.8698e-05\n",
      "Loss ke-161\n",
      "7.869783439673483e-05\n",
      "Proses ke-162\n",
      "Fit ke-162\n",
      "Fit ke-162 End\n",
      "1724/1724 [==============================] - 1s 558us/step - loss: 8.5682e-05\n",
      "Loss ke-162\n",
      "8.56816113810055e-05\n",
      "Proses ke-163\n",
      "Fit ke-163\n",
      "Fit ke-163 End\n",
      "1724/1724 [==============================] - 1s 545us/step - loss: 7.8179e-05\n",
      "Loss ke-163\n",
      "7.817873847670853e-05\n",
      "Proses ke-164\n",
      "Fit ke-164\n",
      "Fit ke-164 End\n",
      "1724/1724 [==============================] - 1s 554us/step - loss: 7.4626e-05\n",
      "Loss ke-164\n",
      "7.462593930540606e-05\n",
      "Proses ke-165\n",
      "Fit ke-165\n",
      "Fit ke-165 End\n",
      "1724/1724 [==============================] - 1s 554us/step - loss: 7.8577e-05\n",
      "Loss ke-165\n",
      "7.857694436097518e-05\n",
      "Proses ke-166\n",
      "Fit ke-166\n",
      "Fit ke-166 End\n",
      "1724/1724 [==============================] - 1s 550us/step - loss: 8.0958e-05\n",
      "Loss ke-166\n",
      "8.095757948467508e-05\n",
      "Proses ke-167\n",
      "Fit ke-167\n",
      "Fit ke-167 End\n",
      "1724/1724 [==============================] - 1s 572us/step - loss: 8.5797e-05\n",
      "Loss ke-167\n",
      "8.579705900046974e-05\n",
      "Proses ke-168\n",
      "Fit ke-168\n",
      "Fit ke-168 End\n",
      "1724/1724 [==============================] - 1s 558us/step - loss: 1.0467e-04\n",
      "Loss ke-168\n",
      "0.00010467488027643412\n",
      "Proses ke-169\n",
      "Fit ke-169\n",
      "Fit ke-169 End\n",
      "1724/1724 [==============================] - 1s 575us/step - loss: 7.7170e-05\n",
      "Loss ke-169\n",
      "7.71701306803152e-05\n",
      "Proses ke-170\n",
      "Fit ke-170\n",
      "Fit ke-170 End\n",
      "1724/1724 [==============================] - 1s 568us/step - loss: 8.6704e-05\n",
      "Loss ke-170\n",
      "8.670410898048431e-05\n",
      "Proses ke-171\n",
      "Fit ke-171\n",
      "Fit ke-171 End\n",
      "1724/1724 [==============================] - 1s 568us/step - loss: 8.5609e-05\n",
      "Loss ke-171\n",
      "8.560899732401595e-05\n",
      "Proses ke-172\n",
      "Fit ke-172\n",
      "Fit ke-172 End\n",
      "1724/1724 [==============================] - 1s 546us/step - loss: 8.5496e-05\n",
      "Loss ke-172\n",
      "8.549590711481869e-05\n",
      "Proses ke-173\n",
      "Fit ke-173\n",
      "Fit ke-173 End\n",
      "1724/1724 [==============================] - 1s 575us/step - loss: 7.4574e-05\n",
      "Loss ke-173\n",
      "7.457444735337049e-05\n",
      "Proses ke-174\n",
      "Fit ke-174\n",
      "Fit ke-174 End\n",
      "1724/1724 [==============================] - 1s 557us/step - loss: 7.6634e-05\n",
      "Loss ke-174\n",
      "7.663429278181866e-05\n",
      "Proses ke-175\n",
      "Fit ke-175\n",
      "Fit ke-175 End\n",
      "1724/1724 [==============================] - 1s 566us/step - loss: 7.4647e-05\n",
      "Loss ke-175\n",
      "7.464707596227527e-05\n",
      "Proses ke-176\n",
      "Fit ke-176\n",
      "Fit ke-176 End\n",
      "1724/1724 [==============================] - 1s 569us/step - loss: 7.9660e-05\n",
      "Loss ke-176\n",
      "7.966025441419333e-05\n",
      "Proses ke-177\n",
      "Fit ke-177\n",
      "Fit ke-177 End\n",
      "1724/1724 [==============================] - 1s 574us/step - loss: 7.8608e-05\n",
      "Loss ke-177\n",
      "7.860813639126718e-05\n",
      "Proses ke-178\n",
      "Fit ke-178\n",
      "Fit ke-178 End\n",
      "1724/1724 [==============================] - 1s 573us/step - loss: 8.8787e-05\n",
      "Loss ke-178\n",
      "8.87867936398834e-05\n",
      "Proses ke-179\n",
      "Fit ke-179\n",
      "Fit ke-179 End\n",
      "1724/1724 [==============================] - 1s 541us/step - loss: 7.6331e-05\n",
      "Loss ke-179\n",
      "7.6331190939527e-05\n",
      "Proses ke-180\n",
      "Fit ke-180\n",
      "Fit ke-180 End\n",
      "1724/1724 [==============================] - 1s 554us/step - loss: 8.0351e-05\n",
      "Loss ke-180\n",
      "8.035095379455015e-05\n",
      "Proses ke-181\n",
      "Fit ke-181\n",
      "Fit ke-181 End\n",
      "1724/1724 [==============================] - 1s 578us/step - loss: 7.8381e-05\n",
      "Loss ke-181\n",
      "7.838116289349273e-05\n",
      "Proses ke-182\n",
      "Fit ke-182\n",
      "Fit ke-182 End\n",
      "1724/1724 [==============================] - 1s 562us/step - loss: 8.8528e-05\n",
      "Loss ke-182\n",
      "8.852844621287659e-05\n",
      "Proses ke-183\n",
      "Fit ke-183\n",
      "Fit ke-183 End\n",
      "1724/1724 [==============================] - 1s 553us/step - loss: 7.4645e-05\n",
      "Loss ke-183\n",
      "7.464507507393137e-05\n",
      "Proses ke-184\n",
      "Fit ke-184\n",
      "Fit ke-184 End\n",
      "1724/1724 [==============================] - 1s 560us/step - loss: 7.8450e-05\n",
      "Loss ke-184\n",
      "7.844964420655742e-05\n",
      "Proses ke-185\n",
      "Fit ke-185\n",
      "Fit ke-185 End\n",
      "1724/1724 [==============================] - 1s 553us/step - loss: 7.4382e-05\n",
      "Loss ke-185\n",
      "7.438159809680656e-05\n",
      "Proses ke-186\n",
      "Fit ke-186\n",
      "Fit ke-186 End\n",
      "1724/1724 [==============================] - 1s 570us/step - loss: 8.2097e-05\n",
      "Loss ke-186\n",
      "8.20971981738694e-05\n",
      "Proses ke-187\n",
      "Fit ke-187\n",
      "Fit ke-187 End\n",
      "1724/1724 [==============================] - 1s 578us/step - loss: 8.0110e-05\n",
      "Loss ke-187\n",
      "8.010979217942804e-05\n",
      "Proses ke-188\n",
      "Fit ke-188\n",
      "Fit ke-188 End\n",
      "1724/1724 [==============================] - 1s 569us/step - loss: 9.1816e-05\n",
      "Loss ke-188\n",
      "9.18159494176507e-05\n",
      "Proses ke-189\n",
      "Fit ke-189\n",
      "Fit ke-189 End\n",
      "1724/1724 [==============================] - 1s 554us/step - loss: 7.6088e-05\n",
      "Loss ke-189\n",
      "7.608848682139069e-05\n",
      "Proses ke-190\n",
      "Fit ke-190\n",
      "Fit ke-190 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 7.5775e-05\n",
      "Loss ke-190\n",
      "7.57752641220577e-05\n",
      "Proses ke-191\n",
      "Fit ke-191\n",
      "Fit ke-191 End\n",
      "1724/1724 [==============================] - 1s 551us/step - loss: 8.1872e-05\n",
      "Loss ke-191\n",
      "8.18715343484655e-05\n",
      "Proses ke-192\n",
      "Fit ke-192\n",
      "Fit ke-192 End\n",
      "1724/1724 [==============================] - 1s 562us/step - loss: 8.7157e-05\n",
      "Loss ke-192\n",
      "8.715713920537382e-05\n",
      "Proses ke-193\n",
      "Fit ke-193\n",
      "Fit ke-193 End\n",
      "1724/1724 [==============================] - 1s 548us/step - loss: 7.4588e-05\n",
      "Loss ke-193\n",
      "7.458771142410114e-05\n",
      "Proses ke-194\n",
      "Fit ke-194\n",
      "Fit ke-194 End\n",
      "1724/1724 [==============================] - 1s 563us/step - loss: 7.7468e-05\n",
      "Loss ke-194\n",
      "7.74678192101419e-05\n",
      "Proses ke-195\n",
      "Fit ke-195\n",
      "Fit ke-195 End\n",
      "1724/1724 [==============================] - 1s 557us/step - loss: 7.4050e-05\n",
      "Loss ke-195\n",
      "7.40499745006673e-05\n",
      "Proses ke-196\n",
      "Fit ke-196\n",
      "Fit ke-196 End\n",
      "1724/1724 [==============================] - 1s 544us/step - loss: 8.3335e-05\n",
      "Loss ke-196\n",
      "8.33349913591519e-05\n",
      "Proses ke-197\n",
      "Fit ke-197\n",
      "Fit ke-197 End\n",
      "1724/1724 [==============================] - 1s 553us/step - loss: 8.2548e-05\n",
      "Loss ke-197\n",
      "8.25476527097635e-05\n",
      "Proses ke-198\n",
      "Fit ke-198\n",
      "Fit ke-198 End\n",
      "1724/1724 [==============================] - 1s 555us/step - loss: 8.2792e-05\n",
      "Loss ke-198\n",
      "8.279232861241326e-05\n",
      "Proses ke-199\n",
      "Fit ke-199\n",
      "Fit ke-199 End\n",
      "1724/1724 [==============================] - 1s 549us/step - loss: 7.4495e-05\n",
      "Loss ke-199\n",
      "7.449541590176523e-05\n",
      "Proses ke-200\n",
      "Fit ke-200\n",
      "Fit ke-200 End\n",
      "1724/1724 [==============================] - 1s 559us/step - loss: 7.9102e-05\n",
      "Loss ke-200\n",
      "7.910239219199866e-05\n",
      "Proses ke-201\n",
      "Fit ke-201\n",
      "Fit ke-201 End\n",
      "1724/1724 [==============================] - 1s 551us/step - loss: 8.0115e-05\n",
      "Loss ke-201\n",
      "8.011527097551152e-05\n",
      "Proses ke-202\n",
      "Fit ke-202\n",
      "Fit ke-202 End\n",
      "1724/1724 [==============================] - 1s 556us/step - loss: 8.1630e-05\n",
      "Loss ke-202\n",
      "8.162992162397131e-05\n",
      "Proses ke-203\n",
      "Fit ke-203\n",
      "Fit ke-203 End\n",
      "1724/1724 [==============================] - 1s 547us/step - loss: 7.5520e-05\n",
      "Loss ke-203\n",
      "7.552038732683286e-05\n",
      "Proses ke-204\n",
      "Fit ke-204\n",
      "Fit ke-204 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 7.5499e-05\n",
      "Loss ke-204\n",
      "7.549931615358219e-05\n",
      "Proses ke-205\n",
      "Fit ke-205\n",
      "Fit ke-205 End\n",
      "1724/1724 [==============================] - 1s 572us/step - loss: 7.4293e-05\n",
      "Loss ke-205\n",
      "7.429317338392138e-05\n",
      "Proses ke-206\n",
      "Fit ke-206\n",
      "Fit ke-206 End\n",
      "1724/1724 [==============================] - 1s 548us/step - loss: 8.3655e-05\n",
      "Loss ke-206\n",
      "8.365458052139729e-05\n",
      "Proses ke-207\n",
      "Fit ke-207\n",
      "Fit ke-207 End\n",
      "1724/1724 [==============================] - 1s 569us/step - loss: 8.5498e-05\n",
      "Loss ke-207\n",
      "8.549752237740904e-05\n",
      "Proses ke-208\n",
      "Fit ke-208\n",
      "Fit ke-208 End\n",
      "1724/1724 [==============================] - 1s 565us/step - loss: 7.8956e-05\n",
      "Loss ke-208\n",
      "7.895629096310586e-05\n",
      "Proses ke-209\n",
      "Fit ke-209\n",
      "Fit ke-209 End\n",
      "1724/1724 [==============================] - 1s 559us/step - loss: 7.8369e-05\n",
      "Loss ke-209\n",
      "7.836890290491283e-05\n",
      "Proses ke-210\n",
      "Fit ke-210\n",
      "Fit ke-210 End\n",
      "1724/1724 [==============================] - 1s 568us/step - loss: 7.8493e-05\n",
      "Loss ke-210\n",
      "7.84929798101075e-05\n",
      "Proses ke-211\n",
      "Fit ke-211\n",
      "Fit ke-211 End\n",
      "1724/1724 [==============================] - 1s 549us/step - loss: 7.9270e-05\n",
      "Loss ke-211\n",
      "7.92695427662693e-05\n",
      "Proses ke-212\n",
      "Fit ke-212\n",
      "Fit ke-212 End\n",
      "1724/1724 [==============================] - 1s 568us/step - loss: 9.1095e-05\n",
      "Loss ke-212\n",
      "9.10954040591605e-05\n",
      "Proses ke-213\n",
      "Fit ke-213\n",
      "Fit ke-213 End\n",
      "1724/1724 [==============================] - 1s 563us/step - loss: 7.8106e-05\n",
      "Loss ke-213\n",
      "7.810588431311771e-05\n",
      "Proses ke-214\n",
      "Fit ke-214\n",
      "Fit ke-214 End\n",
      "1724/1724 [==============================] - 1s 566us/step - loss: 7.4763e-05\n",
      "Loss ke-214\n",
      "7.476298924302682e-05\n",
      "Proses ke-215\n",
      "Fit ke-215\n",
      "Fit ke-215 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 7.6641e-05\n",
      "Loss ke-215\n",
      "7.664115400984883e-05\n",
      "Proses ke-216\n",
      "Fit ke-216\n",
      "Fit ke-216 End\n",
      "1724/1724 [==============================] - 1s 569us/step - loss: 8.6115e-05\n",
      "Loss ke-216\n",
      "8.611468365415931e-05\n",
      "Proses ke-217\n",
      "Fit ke-217\n",
      "Fit ke-217 End\n",
      "1724/1724 [==============================] - 1s 567us/step - loss: 8.0446e-05\n",
      "Loss ke-217\n",
      "8.044626156333834e-05\n",
      "Proses ke-218\n",
      "Fit ke-218\n",
      "Fit ke-218 End\n",
      "1724/1724 [==============================] - 1s 556us/step - loss: 8.1370e-05\n",
      "Loss ke-218\n",
      "8.13700316939503e-05\n",
      "Proses ke-219\n",
      "Fit ke-219\n",
      "Fit ke-219 End\n",
      "1724/1724 [==============================] - 1s 562us/step - loss: 7.8916e-05\n",
      "Loss ke-219\n",
      "7.891604764154181e-05\n",
      "Proses ke-220\n",
      "Fit ke-220\n",
      "Fit ke-220 End\n",
      "1724/1724 [==============================] - 1s 562us/step - loss: 7.9207e-05\n",
      "Loss ke-220\n",
      "7.920696953078732e-05\n",
      "Proses ke-221\n",
      "Fit ke-221\n",
      "Fit ke-221 End\n",
      "1724/1724 [==============================] - 1s 549us/step - loss: 8.2610e-05\n",
      "Loss ke-221\n",
      "8.260964386863634e-05\n",
      "Proses ke-222\n",
      "Fit ke-222\n",
      "Fit ke-222 End\n",
      "1724/1724 [==============================] - 1s 557us/step - loss: 8.9009e-05\n",
      "Loss ke-222\n",
      "8.90086594154127e-05\n",
      "Proses ke-223\n",
      "Fit ke-223\n",
      "Fit ke-223 End\n",
      "1724/1724 [==============================] - 1s 565us/step - loss: 7.8539e-05\n",
      "Loss ke-223\n",
      "7.853946590330452e-05\n",
      "Proses ke-224\n",
      "Fit ke-224\n",
      "Fit ke-224 End\n",
      "1724/1724 [==============================] - 1s 558us/step - loss: 7.6914e-05\n",
      "Loss ke-224\n",
      "7.691369683016092e-05\n",
      "Proses ke-225\n",
      "Fit ke-225\n",
      "Fit ke-225 End\n",
      "1724/1724 [==============================] - 1s 558us/step - loss: 7.6621e-05\n",
      "Loss ke-225\n",
      "7.662058487767354e-05\n",
      "Proses ke-226\n",
      "Fit ke-226\n",
      "Fit ke-226 End\n",
      "1724/1724 [==============================] - 1s 573us/step - loss: 8.6057e-05\n",
      "Loss ke-226\n",
      "8.605670154793188e-05\n",
      "Proses ke-227\n",
      "Fit ke-227\n",
      "Fit ke-227 End\n",
      "1724/1724 [==============================] - 1s 578us/step - loss: 8.2018e-05\n",
      "Loss ke-227\n",
      "8.201827586162835e-05\n",
      "Proses ke-228\n",
      "Fit ke-228\n",
      "Fit ke-228 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 1.0240e-04\n",
      "Loss ke-228\n",
      "0.00010240479605272412\n",
      "Proses ke-229\n",
      "Fit ke-229\n",
      "Fit ke-229 End\n",
      "1724/1724 [==============================] - 1s 578us/step - loss: 7.8455e-05\n",
      "Loss ke-229\n",
      "7.845518121030182e-05\n",
      "Proses ke-230\n",
      "Fit ke-230\n",
      "Fit ke-230 End\n",
      "1724/1724 [==============================] - 1s 555us/step - loss: 8.1602e-05\n",
      "Loss ke-230\n",
      "8.160186553141102e-05\n",
      "Proses ke-231\n",
      "Fit ke-231\n",
      "Fit ke-231 End\n",
      "1724/1724 [==============================] - 1s 545us/step - loss: 8.3922e-05\n",
      "Loss ke-231\n",
      "8.392177551286295e-05\n",
      "Proses ke-232\n",
      "Fit ke-232\n",
      "Fit ke-232 End\n",
      "1724/1724 [==============================] - 1s 585us/step - loss: 8.5581e-05\n",
      "Loss ke-232\n",
      "8.558110857848078e-05\n",
      "Proses ke-233\n",
      "Fit ke-233\n",
      "Fit ke-233 End\n",
      "1724/1724 [==============================] - 1s 590us/step - loss: 7.8269e-05\n",
      "Loss ke-233\n",
      "7.826918590581045e-05\n",
      "Proses ke-234\n",
      "Fit ke-234\n",
      "Fit ke-234 End\n",
      "1724/1724 [==============================] - 1s 567us/step - loss: 7.6361e-05\n",
      "Loss ke-234\n",
      "7.636076770722866e-05\n",
      "Proses ke-235\n",
      "Fit ke-235\n",
      "Fit ke-235 End\n",
      "1724/1724 [==============================] - 1s 584us/step - loss: 7.6504e-05\n",
      "Loss ke-235\n",
      "7.65036020311527e-05\n",
      "Proses ke-236\n",
      "Fit ke-236\n",
      "Fit ke-236 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 8.4885e-05\n",
      "Loss ke-236\n",
      "8.488486491842195e-05\n",
      "Proses ke-237\n",
      "Fit ke-237\n",
      "Fit ke-237 End\n",
      "1724/1724 [==============================] - 1s 566us/step - loss: 8.6007e-05\n",
      "Loss ke-237\n",
      "8.600696310168132e-05\n",
      "Proses ke-238\n",
      "Fit ke-238\n",
      "Fit ke-238 End\n",
      "1724/1724 [==============================] - 1s 566us/step - loss: 8.1257e-05\n",
      "Loss ke-238\n",
      "8.125733438646421e-05\n",
      "Proses ke-239\n",
      "Fit ke-239\n",
      "Fit ke-239 End\n",
      "1724/1724 [==============================] - 1s 568us/step - loss: 7.8128e-05\n",
      "Loss ke-239\n",
      "7.812766853021458e-05\n",
      "Proses ke-240\n",
      "Fit ke-240\n",
      "Fit ke-240 End\n",
      "1724/1724 [==============================] - 1s 570us/step - loss: 8.4175e-05\n",
      "Loss ke-240\n",
      "8.417474600719288e-05\n",
      "Proses ke-241\n",
      "Fit ke-241\n",
      "Fit ke-241 End\n",
      "1724/1724 [==============================] - 1s 580us/step - loss: 8.0488e-05\n",
      "Loss ke-241\n",
      "8.048821473494172e-05\n",
      "Proses ke-242\n",
      "Fit ke-242\n",
      "Fit ke-242 End\n",
      "1724/1724 [==============================] - 1s 571us/step - loss: 8.5952e-05\n",
      "Loss ke-242\n",
      "8.595174585934728e-05\n",
      "Proses ke-243\n",
      "Fit ke-243\n",
      "Fit ke-243 End\n",
      "1724/1724 [==============================] - 1s 570us/step - loss: 7.6559e-05\n",
      "Loss ke-243\n",
      "7.655940135009587e-05\n",
      "Proses ke-244\n",
      "Fit ke-244\n",
      "Fit ke-244 End\n",
      "1724/1724 [==============================] - 1s 571us/step - loss: 7.6295e-05\n",
      "Loss ke-244\n",
      "7.629469473613426e-05\n",
      "Proses ke-245\n",
      "Fit ke-245\n",
      "Fit ke-245 End\n",
      "1724/1724 [==============================] - 1s 548us/step - loss: 7.4135e-05\n",
      "Loss ke-245\n",
      "7.413508137688041e-05\n",
      "Proses ke-246\n",
      "Fit ke-246\n",
      "Fit ke-246 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 8.4404e-05\n",
      "Loss ke-246\n",
      "8.440397505182773e-05\n",
      "Proses ke-247\n",
      "Fit ke-247\n",
      "Fit ke-247 End\n",
      "1724/1724 [==============================] - 1s 576us/step - loss: 8.4117e-05\n",
      "Loss ke-247\n",
      "8.411717135459185e-05\n",
      "Proses ke-248\n",
      "Fit ke-248\n",
      "Fit ke-248 End\n",
      "1724/1724 [==============================] - 1s 559us/step - loss: 1.0787e-04\n",
      "Loss ke-248\n",
      "0.00010786624625325203\n",
      "Proses ke-249\n",
      "Fit ke-249\n",
      "Fit ke-249 End\n",
      "1724/1724 [==============================] - 1s 553us/step - loss: 7.8628e-05\n",
      "Loss ke-249\n",
      "7.862763595767319e-05\n",
      "Proses ke-250\n",
      "Fit ke-250\n",
      "Fit ke-250 End\n",
      "1724/1724 [==============================] - 1s 553us/step - loss: 8.7012e-05\n",
      "Loss ke-250\n",
      "8.701232582097873e-05\n",
      "Proses ke-251\n",
      "Fit ke-251\n",
      "Fit ke-251 End\n",
      "1724/1724 [==============================] - 1s 562us/step - loss: 7.8412e-05\n",
      "Loss ke-251\n",
      "7.84116200520657e-05\n",
      "Proses ke-252\n",
      "Fit ke-252\n",
      "Fit ke-252 End\n",
      "1724/1724 [==============================] - 1s 565us/step - loss: 8.2724e-05\n",
      "Loss ke-252\n",
      "8.272354170912877e-05\n",
      "Proses ke-253\n",
      "Fit ke-253\n",
      "Fit ke-253 End\n",
      "1724/1724 [==============================] - 1s 560us/step - loss: 7.7168e-05\n",
      "Loss ke-253\n",
      "7.716790423728526e-05\n",
      "Proses ke-254\n",
      "Fit ke-254\n",
      "Fit ke-254 End\n",
      "1724/1724 [==============================] - 1s 559us/step - loss: 7.7007e-05\n",
      "Loss ke-254\n",
      "7.700671267230064e-05\n",
      "Proses ke-255\n",
      "Fit ke-255\n",
      "Fit ke-255 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 7.6642e-05\n",
      "Loss ke-255\n",
      "7.664193253731355e-05\n",
      "Proses ke-256\n",
      "Fit ke-256\n",
      "Fit ke-256 End\n",
      "1724/1724 [==============================] - 1s 563us/step - loss: 8.4449e-05\n",
      "Loss ke-256\n",
      "8.444885315839201e-05\n",
      "Proses ke-257\n",
      "Fit ke-257\n",
      "Fit ke-257 End\n",
      "1724/1724 [==============================] - 1s 572us/step - loss: 8.2754e-05\n",
      "Loss ke-257\n",
      "8.27536205179058e-05\n",
      "Proses ke-258\n",
      "Fit ke-258\n",
      "Fit ke-258 End\n",
      "1724/1724 [==============================] - 1s 577us/step - loss: 9.9741e-05\n",
      "Loss ke-258\n",
      "9.974063141271472e-05\n",
      "Proses ke-259\n",
      "Fit ke-259\n",
      "Fit ke-259 End\n",
      "1724/1724 [==============================] - 1s 576us/step - loss: 7.6503e-05\n",
      "Loss ke-259\n",
      "7.650320185348392e-05\n",
      "Proses ke-260\n",
      "Fit ke-260\n",
      "Fit ke-260 End\n",
      "1724/1724 [==============================] - 1s 542us/step - loss: 8.4769e-05\n",
      "Loss ke-260\n",
      "8.476926450384781e-05\n",
      "Proses ke-261\n",
      "Fit ke-261\n",
      "Fit ke-261 End\n",
      "1724/1724 [==============================] - 1s 560us/step - loss: 8.2264e-05\n",
      "Loss ke-261\n",
      "8.226429781643674e-05\n",
      "Proses ke-262\n",
      "Fit ke-262\n",
      "Fit ke-262 End\n",
      "1724/1724 [==============================] - 1s 540us/step - loss: 9.0836e-05\n",
      "Loss ke-262\n",
      "9.083638724405318e-05\n",
      "Proses ke-263\n",
      "Fit ke-263\n",
      "Fit ke-263 End\n",
      "1724/1724 [==============================] - 1s 559us/step - loss: 7.5676e-05\n",
      "Loss ke-263\n",
      "7.567623106297106e-05\n",
      "Proses ke-264\n",
      "Fit ke-264\n",
      "Fit ke-264 End\n",
      "1724/1724 [==============================] - 1s 567us/step - loss: 7.6796e-05\n",
      "Loss ke-264\n",
      "7.679637928958982e-05\n",
      "Proses ke-265\n",
      "Fit ke-265\n",
      "Fit ke-265 End\n",
      "1724/1724 [==============================] - 1s 545us/step - loss: 7.4509e-05\n",
      "Loss ke-265\n",
      "7.45086363167502e-05\n",
      "Proses ke-266\n",
      "Fit ke-266\n",
      "Fit ke-266 End\n",
      "1724/1724 [==============================] - 1s 553us/step - loss: 8.5174e-05\n",
      "Loss ke-266\n",
      "8.517399692209437e-05\n",
      "Proses ke-267\n",
      "Fit ke-267\n",
      "Fit ke-267 End\n",
      "1724/1724 [==============================] - 1s 568us/step - loss: 7.9724e-05\n",
      "Loss ke-267\n",
      "7.972383900778368e-05\n",
      "Proses ke-268\n",
      "Fit ke-268\n",
      "Fit ke-268 End\n",
      "1724/1724 [==============================] - 1s 562us/step - loss: 1.1526e-04\n",
      "Loss ke-268\n",
      "0.00011526182788657025\n",
      "Proses ke-269\n",
      "Fit ke-269\n",
      "Fit ke-269 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 7.8356e-05\n",
      "Loss ke-269\n",
      "7.835636642994359e-05\n",
      "Proses ke-270\n",
      "Fit ke-270\n",
      "Fit ke-270 End\n",
      "1724/1724 [==============================] - 1s 578us/step - loss: 7.7136e-05\n",
      "Loss ke-270\n",
      "7.713638478890061e-05\n",
      "Proses ke-271\n",
      "Fit ke-271\n",
      "Fit ke-271 End\n",
      "1724/1724 [==============================] - 1s 554us/step - loss: 8.2646e-05\n",
      "Loss ke-271\n",
      "8.264649659395218e-05\n",
      "Proses ke-272\n",
      "Fit ke-272\n",
      "Fit ke-272 End\n",
      "1724/1724 [==============================] - 1s 554us/step - loss: 8.9645e-05\n",
      "Loss ke-272\n",
      "8.964549488155171e-05\n",
      "Proses ke-273\n",
      "Fit ke-273\n",
      "Fit ke-273 End\n",
      "1724/1724 [==============================] - 1s 552us/step - loss: 7.4478e-05\n",
      "Loss ke-273\n",
      "7.447773532476276e-05\n",
      "Proses ke-274\n",
      "Fit ke-274\n",
      "Fit ke-274 End\n",
      "1724/1724 [==============================] - 1s 559us/step - loss: 7.5192e-05\n",
      "Loss ke-274\n",
      "7.519195787608624e-05\n",
      "Proses ke-275\n",
      "Fit ke-275\n",
      "Fit ke-275 End\n",
      "1724/1724 [==============================] - 1s 569us/step - loss: 7.4158e-05\n",
      "Loss ke-275\n",
      "7.415773870889097e-05\n",
      "Proses ke-276\n",
      "Fit ke-276\n",
      "Fit ke-276 End\n",
      "1724/1724 [==============================] - 1s 547us/step - loss: 8.6509e-05\n",
      "Loss ke-276\n",
      "8.65091715240851e-05\n",
      "Proses ke-277\n",
      "Fit ke-277\n",
      "Fit ke-277 End\n",
      "1724/1724 [==============================] - 1s 565us/step - loss: 8.4862e-05\n",
      "Loss ke-277\n",
      "8.486217120662332e-05\n",
      "Proses ke-278\n",
      "Fit ke-278\n",
      "Fit ke-278 End\n",
      "1724/1724 [==============================] - 1s 560us/step - loss: 9.9843e-05\n",
      "Loss ke-278\n",
      "9.984321513911709e-05\n",
      "Proses ke-279\n",
      "Fit ke-279\n",
      "Fit ke-279 End\n",
      "1724/1724 [==============================] - 1s 585us/step - loss: 7.8357e-05\n",
      "Loss ke-279\n",
      "7.835694123059511e-05\n",
      "Proses ke-280\n",
      "Fit ke-280\n",
      "Fit ke-280 End\n",
      "1724/1724 [==============================] - 1s 562us/step - loss: 8.0358e-05\n",
      "Loss ke-280\n",
      "8.035804785322398e-05\n",
      "Proses ke-281\n",
      "Fit ke-281\n",
      "Fit ke-281 End\n",
      "1724/1724 [==============================] - 1s 557us/step - loss: 8.4176e-05\n",
      "Loss ke-281\n",
      "8.417599747190252e-05\n",
      "Proses ke-282\n",
      "Fit ke-282\n",
      "Fit ke-282 End\n",
      "1724/1724 [==============================] - 1s 568us/step - loss: 8.2390e-05\n",
      "Loss ke-282\n",
      "8.238998270826414e-05\n",
      "Proses ke-283\n",
      "Fit ke-283\n",
      "Fit ke-283 End\n",
      "1724/1724 [==============================] - 1s 570us/step - loss: 7.4477e-05\n",
      "Loss ke-283\n",
      "7.447689858963713e-05\n",
      "Proses ke-284\n",
      "Fit ke-284\n",
      "Fit ke-284 End\n",
      "1724/1724 [==============================] - 1s 552us/step - loss: 7.7226e-05\n",
      "Loss ke-284\n",
      "7.722626469330862e-05\n",
      "Proses ke-285\n",
      "Fit ke-285\n",
      "Fit ke-285 End\n",
      "1724/1724 [==============================] - 1s 556us/step - loss: 7.6477e-05\n",
      "Loss ke-285\n",
      "7.647719030501321e-05\n",
      "Proses ke-286\n",
      "Fit ke-286\n",
      "Fit ke-286 End\n",
      "1724/1724 [==============================] - 1s 560us/step - loss: 8.4023e-05\n",
      "Loss ke-286\n",
      "8.402342064073309e-05\n",
      "Proses ke-287\n",
      "Fit ke-287\n",
      "Fit ke-287 End\n",
      "1724/1724 [==============================] - 1s 556us/step - loss: 8.5253e-05\n",
      "Loss ke-287\n",
      "8.525256271241233e-05\n",
      "Proses ke-288\n",
      "Fit ke-288\n",
      "Fit ke-288 End\n",
      "1724/1724 [==============================] - 1s 549us/step - loss: 8.8830e-05\n",
      "Loss ke-288\n",
      "8.883022383088246e-05\n",
      "Proses ke-289\n",
      "Fit ke-289\n",
      "Fit ke-289 End\n",
      "1724/1724 [==============================] - 1s 560us/step - loss: 7.8719e-05\n",
      "Loss ke-289\n",
      "7.871886919019744e-05\n",
      "Proses ke-290\n",
      "Fit ke-290\n",
      "Fit ke-290 End\n",
      "1724/1724 [==============================] - 1s 561us/step - loss: 7.9681e-05\n",
      "Loss ke-290\n",
      "7.968094723764807e-05\n",
      "Proses ke-291\n",
      "Fit ke-291\n",
      "Fit ke-291 End\n",
      "1724/1724 [==============================] - 1s 565us/step - loss: 8.3215e-05\n",
      "Loss ke-291\n",
      "8.321453060489148e-05\n",
      "Proses ke-292\n",
      "Fit ke-292\n",
      "Fit ke-292 End\n",
      "1724/1724 [==============================] - 1s 570us/step - loss: 9.4098e-05\n",
      "Loss ke-292\n",
      "9.409816993866116e-05\n",
      "Proses ke-293\n",
      "Fit ke-293\n",
      "Fit ke-293 End\n",
      "1724/1724 [==============================] - 1s 586us/step - loss: 7.7941e-05\n",
      "Loss ke-293\n",
      "7.79414622229524e-05\n",
      "Proses ke-294\n",
      "Fit ke-294\n",
      "Fit ke-294 End\n",
      "1724/1724 [==============================] - 1s 555us/step - loss: 7.4567e-05\n",
      "Loss ke-294\n",
      "7.456690218532458e-05\n",
      "Proses ke-295\n",
      "Fit ke-295\n",
      "Fit ke-295 End\n",
      "1724/1724 [==============================] - 1s 558us/step - loss: 7.6475e-05\n",
      "Loss ke-295\n",
      "7.647494203411043e-05\n",
      "Proses ke-296\n",
      "Fit ke-296\n",
      "Fit ke-296 End\n",
      "1724/1724 [==============================] - 1s 576us/step - loss: 8.1522e-05\n",
      "Loss ke-296\n",
      "8.152150985551998e-05\n",
      "Proses ke-297\n",
      "Fit ke-297\n",
      "Fit ke-297 End\n",
      "1724/1724 [==============================] - 1s 602us/step - loss: 8.3163e-05\n",
      "Loss ke-297\n",
      "8.316343883052468e-05\n",
      "Proses ke-298\n",
      "Fit ke-298\n",
      "Fit ke-298 End\n",
      "1724/1724 [==============================] - 1s 571us/step - loss: 8.9738e-05\n",
      "Loss ke-298\n",
      "8.973802323453128e-05\n",
      "Proses ke-299\n",
      "Fit ke-299\n",
      "Fit ke-299 End\n",
      "1724/1724 [==============================] - 1s 570us/step - loss: 7.4819e-05\n",
      "Loss ke-299\n",
      "7.481871580239385e-05\n",
      "Proses ke-300\n",
      "Fit ke-300\n",
      "Fit ke-300 End\n",
      "1724/1724 [==============================] - 1s 578us/step - loss: 8.0915e-05\n",
      "Loss ke-300\n",
      "8.091509516816586e-05\n",
      "Proses ke-301\n",
      "Fit ke-301\n",
      "Fit ke-301 End\n",
      "1724/1724 [==============================] - 1s 565us/step - loss: 8.0501e-05\n",
      "Loss ke-301\n",
      "8.050134783843532e-05\n",
      "Proses ke-302\n",
      "Fit ke-302\n",
      "Fit ke-302 End\n",
      "1724/1724 [==============================] - 1s 577us/step - loss: 9.1828e-05\n",
      "Loss ke-302\n",
      "9.182784560834989e-05\n",
      "Proses ke-303\n",
      "Fit ke-303\n",
      "Fit ke-303 End\n",
      "1724/1724 [==============================] - 1s 553us/step - loss: 7.4984e-05\n",
      "Loss ke-303\n",
      "7.498394552385435e-05\n",
      "Proses ke-304\n",
      "Fit ke-304\n",
      "Fit ke-304 End\n",
      "1724/1724 [==============================] - 1s 560us/step - loss: 7.4653e-05\n",
      "Loss ke-304\n",
      "7.465326780220494e-05\n",
      "Proses ke-305\n",
      "Fit ke-305\n",
      "Fit ke-305 End\n",
      "1724/1724 [==============================] - 1s 550us/step - loss: 7.4046e-05\n",
      "Loss ke-305\n",
      "7.404568168567494e-05\n",
      "Stopping search: Swarm best objective change less than 1e-08\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "index = 0\n",
    "\n",
    "# Membuat dataset TensorFlow dari data Anda\n",
    "# Menggunakan data yang telah Anda baca dari berkas CSV\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "batch_size = 64\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, y)).batch(batch_size)\n",
    "\n",
    "# Menambahkan metode prefetch() ke dataset\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Fungsi objektif untuk PSO (menggunakan MSE sebagai objektif)\n",
    "def objective_function(params):\n",
    "    global index\n",
    "    print(f'Proses ke-{index}')\n",
    "\n",
    "    # Membangun model jaringan saraf tiruan\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(10, input_dim=data.shape[1] - 1, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    # Set parameter berdasarkan hasil optimasi PSO\n",
    "    num_input_units = data.shape[1] - 1\n",
    "    num_hidden_units = 10\n",
    "    num_output_units = 1\n",
    "    \n",
    "    num_weights_layer1 = num_input_units * num_hidden_units\n",
    "    num_bias_layer1 = num_hidden_units\n",
    "    num_weights_layer2 = num_hidden_units * num_output_units\n",
    "    num_bias_layer2 = num_output_units\n",
    "    \n",
    "    weights_layer1 = params[:num_weights_layer1].reshape((num_input_units, num_hidden_units))\n",
    "    bias_layer1 = params[num_weights_layer1:num_weights_layer1 + num_bias_layer1]\n",
    "    weights_layer2 = params[-num_weights_layer2 - num_bias_layer2:-num_bias_layer2].reshape((num_hidden_units, num_output_units))\n",
    "    bias_layer2 = params[-num_bias_layer2:]\n",
    "    \n",
    "    model.layers[0].set_weights([weights_layer1, bias_layer1])\n",
    "    model.layers[1].set_weights([weights_layer2, bias_layer2])\n",
    "    \n",
    "    # Kompilasi model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    # Latih model\n",
    "    print(f'Fit ke-{index}')\n",
    "    model.fit(dataset, epochs=100, verbose=0)\n",
    "    print(f'Fit ke-{index} End')\n",
    "    \n",
    "    # Evaluasi model dan mengembalikan nilai yang ingin dioptimasi\n",
    "    loss = model.evaluate(X, y, verbose=1)\n",
    "    print(f'Loss ke-{index}')\n",
    "    print(loss)\n",
    "    index += 1\n",
    "    return loss\n",
    "\n",
    "# Batasan parameter untuk PSO\n",
    "num_input_units = data.shape[1] - 1\n",
    "num_hidden_units = 10\n",
    "num_output_units = 1\n",
    "\n",
    "num_weights_layer1 = num_input_units * num_hidden_units\n",
    "num_bias_layer1 = num_hidden_units\n",
    "num_weights_layer2 = num_hidden_units * num_output_units\n",
    "num_bias_layer2 = num_output_units\n",
    "\n",
    "num_parameters = num_weights_layer1 + num_bias_layer1 + num_weights_layer2 + num_bias_layer2\n",
    "lb = [-1.0] * num_parameters  # Batas bawah parameter\n",
    "ub = [1.0] * num_parameters   # Batas atas parameter\n",
    "\n",
    "# Jalankan PSO untuk mengoptimasi parameter jaringan\n",
    "best_params, _ = pso(objective_function, lb, ub, swarmsize=10, maxiter=50)\n",
    "\n",
    "# Bangun model jaringan saraf tiruan dengan parameter terbaik\n",
    "best_model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_dim=num_input_units, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "weights_layer1 = best_params[:num_weights_layer1].reshape((num_input_units, num_hidden_units))\n",
    "bias_layer1 = best_params[num_weights_layer1:num_weights_layer1 + num_bias_layer1]\n",
    "weights_layer2 = best_params[-num_weights_layer2 - num_bias_layer2:-num_bias_layer2].reshape((num_hidden_units, num_output_units))\n",
    "bias_layer2 = best_params[-num_bias_layer2:]\n",
    "best_model.layers[0].set_weights([weights_layer1, bias_layer1])\n",
    "best_model.layers[1].set_weights([weights_layer2, bias_layer2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ww-pc/anaconda3/envs/ecg-pee/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Simpan model terbaik ke dalam berkas H5\n",
    "best_model.save(\"ann_pso_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.6345068]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('ann_pso_v2.h5')\n",
    "model.predict([[0.145,-0.145,-0.145,-0.145]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
